{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNCTGYgT8udDUmTMSZkFRqM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayNguyen-123/Brain_Tumor_Detection_with_Pytorch/blob/main/Pytorch_Brain_tumor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDPOD_AsrrXT"
      },
      "outputs": [],
      "source": [
        "# Check if CUDA is available\n",
        "print(f\"Is CUDA supported by this system? {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Convolution Neural Network for Brain Tumor Detection and Diagnosis\n"
      ],
      "metadata": {
        "id": "UV77AKTlsDw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install split-folders\n",
        "!pip install torch-summary\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvQu_4w2sQgH",
        "outputId": "c6f7d489-2b3f-43dd-c6d2-63ed81f5b6b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n",
            "Collecting torch-summary\n",
            "  Downloading torch_summary-1.4.5-py3-none-any.whl.metadata (18 kB)\n",
            "Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: torch-summary\n",
            "Successfully installed torch-summary-1.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set(style='darkgrid')\n",
        "import copy\n",
        "import os\n",
        "import torch\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import random_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.nn as nn\n",
        "from torchvision import utils\n",
        "from torchvision.datasets import ImageFolder\n",
        "import splitfolders\n",
        "from torchsummary import summary\n",
        "import torch.nn.functional as F\n",
        "import pathlib\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "from tqdm.notebook import trange, tqdm\n",
        "from torch import optim\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "qOuEEh41sgu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction\n",
        "Deep Learning has emerged as a powerful tool in the field of medical imaging and has shown great potential in aiding the health community in the detection and diagnosis of brain tumors. By leveraging deep learning algorithms, we can analyze medical images, such as MRI or CT scans, with unprecedented accuracy and efficiency.\n",
        "By leveraging the power of neural networks, we can enhance the accuracy, efficiency, and understanding of brain tumor imaging, ultimately leading to improved patient care and outcomes in the field of neuro-oncology.\n"
      ],
      "metadata": {
        "id": "x0dGgEo9uq28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset\n"
      ],
      "metadata": {
        "id": "cZAtCcvRvExA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df = pd.read_csv('/content/metadata.csv')\n",
        "print(labels_df.head().to_markdown())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJIIUFKBu-Q8",
        "outputId": "8f4698cb-5620-4d3b-feb5-2baa47bacf2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|    |   Unnamed: 0 | image           | class   | format   | mode   | shape         |\n",
            "|---:|-------------:|:----------------|:--------|:---------|:-------|:--------------|\n",
            "|  0 |            0 | Cancer (1).jpg  | tumor   | JPEG     | RGB    | (512, 512, 3) |\n",
            "|  1 |            1 | Cancer (1).png  | tumor   | PNG      | L      | (300, 240)    |\n",
            "|  2 |            2 | Cancer (1).tif  | tumor   | TIFF     | RGB    | (256, 256, 3) |\n",
            "|  3 |            3 | Cancer (10).jpg | tumor   | JPEG     | RGB    | (512, 512, 3) |\n",
            "|  4 |            4 | Cancer (10).tif | tumor   | TIFF     | RGB    | (256, 256, 3) |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('')\n"
      ],
      "metadata": {
        "id": "D_jAJPfMulEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_df.shape\n"
      ],
      "metadata": {
        "id": "K5UEj0ru8SCC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation\n",
        "We need to evaluate the model on validation datasets to track the model's performance during training. Then, Let's use 20% of the dataset for the Validation set and use the rest as the Training set, so we have an 80/20 split!"
      ],
      "metadata": {
        "id": "1fEM6nOV8Za6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# dataset path\n",
        "data_dir = ('')\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "\n",
        "# # splitting dataset to train_set, val_set and test_set\n",
        "splitfolders.ratio(data_dir, output='brain', seed=20, ratio=(0.8, 0.2))\n",
        "\n",
        "# new dataset path\n",
        "data_dir = ''\n",
        "data_dir = pathlib.Path(data_dir)\n"
      ],
      "metadata": {
        "id": "w9jsNU4p8gMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Image Augmentation Definitions"
      ],
      "metadata": {
        "id": "1pZjbpQ99kVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256,256)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomVerticalFlip(p=0.5),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ],
      "metadata": {
        "id": "0HizZEzH9o3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define an object of the custom dataset for the train and validation\n",
        "train_set = torchvision.datasets.ImageFolder(data_dir.joinpath('train'), transform=transform)\n",
        "train_set.transform\n",
        "val_set = torchvision.datasets.ImageFolder(data_dir.joinpath('Val'), transform=transform)\n",
        "val_set.transform\n"
      ],
      "metadata": {
        "id": "yNxL2zB0-sf2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# visualization some images from the train set\n",
        "CLA_label = {\n",
        "    0: \"Brain Tumor\",\n",
        "    1: \"Healthy\"\n",
        "}\n",
        "\n",
        "figure = plt.figure(figsize=(10,10))\n",
        "cols, rows = 4,4\n",
        "for i in range(1, cols*rows + 1):\n",
        "  sample_idx = torch.randint(len(train_set), size=(1,)).item()\n",
        "  img, label = train_set[sample_idx]\n",
        "  figure.add_subplot(rows, cols, i)\n",
        "  plt.title(CLA_label[label])\n",
        "  plt.axis(\"off\")\n",
        "  img_np = img.numpy().transpose((1, 2, 0))\n",
        "\n",
        "  # clip pixel values to [0,1]\n",
        "  img_valid_range = np.clip(img_np, 0, 1)\n",
        "  plt.imshow(img_valid_range)\n",
        "  plt.suptitle(\"Brain Images\", y=0.95)\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "X4LMFKkX_g_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cSLdS82tBw5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Dataloader\n"
      ],
      "metadata": {
        "id": "YVhxTGl8Byvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import and load train, validation\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n"
      ],
      "metadata": {
        "id": "3dtQ-u-yB43r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print shape for training data and validation data\n",
        "for key, value in {'Traning data': train_loader, 'Validation data': val_loader}.items():\n",
        "  for X, y in value:\n",
        "    print(f\"{key}:\")\n",
        "    print(f\"Shape of X : {X.shape}\")\n",
        "    print(f\"Shape of y : {y.shape} {y.dtype}\\n\")\n",
        "    break\n",
        "\n"
      ],
      "metadata": {
        "id": "J_3FcsHwCghZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Brain Tumor Classifier\n"
      ],
      "metadata": {
        "id": "gvBbLEHmDrPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_conv2d_shape(hin, win, conv, pool=2):\n",
        "  # get conv arguments\n",
        "  kernel_size = conv.kernel_size\n",
        "  stride = conv.stride\n",
        "  padding = conv.padding\n",
        "  dilation = conv.dilation\n",
        "\n",
        "  hout = np.floor((hin+2*padding[0]-dilation[0]*(kernel_size[0]-1)-1)/stride[0]+1)\n",
        "  wout = np.floor((win+2*padding[1]-dilation[1]*(kernel_size[1]-1)-1)/stride[1]+1)\n",
        "\n",
        "  if pool:\n",
        "    hout/=pool\n",
        "    wout/=pool\n",
        "\n",
        "  return int(hout), int(wout)\n",
        "\n"
      ],
      "metadata": {
        "id": "3cZWNoDyDw_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define Architecture for CNN model\n",
        "class CNN_Tumor(nn.Module):\n",
        "  # network initialization\n",
        "  def __init__(self, params):\n",
        "    super(CNN_Tumor, self).__init__()\n",
        "\n",
        "    Cin, Hin, Win = params[\"shape in\"]\n",
        "    init_f = params[\"initial_filter\"]\n",
        "    num_fc1 = params[\"num_fc1\"]\n",
        "    num_classes = params[\"num_classes\"]\n",
        "    self.dropout_rate = params[\"dropout_rate\"]\n",
        "\n",
        "    # convolution layers\n",
        "    self.conv1 = nn.Conv2d(Cin, init_f, kernel_size=3)\n",
        "    h,w = find_conv2d_shape(Hin,Win,self.conv1)\n",
        "\n",
        "    self.conv2 = nn.Conv2d(init_f, 2*init_f, kernel_size=3)\n",
        "    h,w = find_conv2d_shape(h,w,self.conv2)\n",
        "\n",
        "    self.conv3 = nn.Conv2d(2*init_f, 4*init_f, kernel_size=3)\n",
        "    h,w = find_conv2d_shape(h,w,self.conv3)\n",
        "\n",
        "    self.conv4 = nn.Conv2d(4*init_f, 8*init_f, kernel_size=3)\n",
        "    h,w = find_conv2d_shape(h,w,self.conv4)\n",
        "\n",
        "    # compute the flatten size\n",
        "    self.num_flatten = h*w*8*init_f\n",
        "    self.fc1 = nn.Linear(self.num_flatten, num_fc1)\n",
        "    self.fc2 = nn.Linear(num_fc1, num_classes)\n",
        "\n",
        "def forward(self, X):\n",
        "\n",
        "  # convolution & pool layers\n",
        "  X = F.relu(self.conv1(X));\n",
        "  X = F.max_pool2d(X, 2 ,2)\n",
        "  X = F.relu(self.conv2(X))\n",
        "  X = F.max_pool2d(X, 2, 2)\n",
        "  X = F.relu(self.conv3(X))\n",
        "  X = F.max_pool2d(X, 2, 2)\n",
        "  X = F.relu(self.conv4(X))\n",
        "  X = F.max_pool2d(X, 2, 2)\n",
        "  X = X.view(-1, self.num_flatten)\n",
        "  X = F.relu(self.fc1(X))\n",
        "  X = F.dropout(X, self.dropout_rate)\n",
        "  X = self.fc2(X)\n",
        "  return F.log_softmax(X, dim=1)\n",
        "\n",
        "params_model = {\n",
        "    \"shape_in\": (3,256,256),\n",
        "    \"initial_filters\": 8,\n",
        "    \"num_fc1\": 100,\n",
        "    \"dropout_rate\": 0.25,\n",
        "    \"num_classes\": 2\n",
        "}\n",
        "\n",
        "# create instantiation of network class\n",
        "cnn_model = CNN_Tumor(params_model)\n",
        "\n",
        "# define computaion hardware approach(GPU/CPU)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = cnn_model.to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "UqW95GYiFMI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Summary for CNN model\n",
        "summary(cnn_model, input_size=(3, 256, 256), device=device.type)\n"
      ],
      "metadata": {
        "id": "4sA7mPxJLSlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loss Function Definition"
      ],
      "metadata": {
        "id": "ydCIhtanLkeG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.NLLLoss(reduction=\"sum\")"
      ],
      "metadata": {
        "id": "y0DHRFuPLoi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer Definition\n"
      ],
      "metadata": {
        "id": "6j3JLYUdMImr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optim.Adam(cnn_model.parameters(), lr=3e-4)\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode='min',factor=0.5, patience=20,verbose=1)\n"
      ],
      "metadata": {
        "id": "0tD5GL3aMMAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Model\n"
      ],
      "metadata": {
        "id": "MlA3QN48MZNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to get the learning rate\n",
        "def get_lr(opt):\n",
        "  for param_group in opt.param_groups:\n",
        "    return param_group['lr']\n",
        "\n",
        "# function to compute the loss value per batch of data\n",
        "def loss_batch(loss_func, output, target, opt=None):\n",
        "  loss = loss_func(output, target) # to get Loss\n",
        "  pred = output.argmax(dim=1, keepdim=True) # get Output class\n",
        "  metric_b = pred.eq(target.view_as(pred)).sum().item() # get performance metrics\n",
        "\n",
        "  if opt is not None:\n",
        "    opt.zero_grad()\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "  return loss.item(), metric_b\n",
        "\n",
        "# compute the loss value & performance metric for the entire dataset(epoch)\n",
        "def loss_epoch(model, loss_func, dataset_dl, opt=None):\n",
        "\n",
        "  run_loss = 0.0\n",
        "  t_metric = 0.0\n",
        "  len_data = len(dataset_dl.dataset)\n",
        "\n",
        "  # internal loop over dataset\n",
        "  for xb, yb in dataset_dl:\n",
        "    xb= xb.to(device)\n",
        "    yb = yb.to(device)\n",
        "    output = model(xb) # get model output\n",
        "    loss_b, metric_b = loss_batch(loss_func, output, yb, opt) # get loss per batch\n",
        "    run_loss += loss_b # update running loss\n",
        "\n",
        "    if metric_b is not None:\n",
        "       # update running metric\n",
        "      t_metric += metric_b\n",
        "\n",
        "  loss = run_loss/float(len_data) # average loss value\n",
        "  metric = t_metric/float(len_data) # average metric value\n",
        "\n",
        "  return loss, metric\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jvJlFYSlMGOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Function\n"
      ],
      "metadata": {
        "id": "HbCvGJV0P2CW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_val(model, params, verbose=False):\n",
        "\n",
        "  # get the parameters\n",
        "  epochs = params['epochs']\n",
        "  loss_func = params['f_loss']\n",
        "  opt = params['optimizer']\n",
        "  train_dl = params['train']\n",
        "  val_dl = params['val']\n",
        "  lr_scheduler = params['lr_change']\n",
        "  weight_path = params['weight_path']\n",
        "\n",
        "  # history of loss values in each epoch\n",
        "  loss_history = {'train': [], 'val': []}\n",
        "  # history of metric values in each epoch\n",
        "  metric_history = {'train': [], 'val': []}\n",
        "  # a deep copy of weight for the best performing model\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "  # initialize best loss to a large value\n",
        "  best_loss = float('inf')\n",
        "\n",
        "  # Train model n_epochs\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "\n",
        "    # get the learning rate\n",
        "    current_lr = get_lr(opt)\n",
        "    if(verbose):\n",
        "      print('Epoch {}/{}, current lr=[]', format(epoch, epochs-1, current_lr))\n",
        "\n",
        "    model.train()\n",
        "    train_loss, train_metric = loss_epoch(model, loss_func, train_dl, opt)\n",
        "\n",
        "    # collect losses\n",
        "    loss_history['train'].append(train_loss)\n",
        "    metric_history['train'].append(train_metric)\n",
        "\n",
        "    # evaluate model process\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      val_loss, val_metric = loss_epoch(model, loss_func, val_dl)\n",
        "\n",
        "    # store best model\n",
        "    if(val_loss < best_loss):\n",
        "      best_loss = val_loss\n",
        "      best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "      # store weights into a local file\n",
        "      torch.save(model.state_dict(), weight_path)\n",
        "      if(verbose):\n",
        "        print(\"Copied best model weights\")\n",
        "\n",
        "    # collect loss and metric for a validation dataset\n",
        "    loss_history['val'].append(val_loss)\n",
        "    metric_history['val'].append(val_metric)\n",
        "\n",
        "    # learning rate schedule\n",
        "    lr_scheduler.step(val_loss)\n",
        "    if current_lr != get_lr(opt):\n",
        "      if(verbose):\n",
        "        print(\"Loading best model weights!\")\n",
        "      model.load_state_dict(best_model_wts)\n",
        "\n",
        "    if(verbose):\n",
        "      print(f\"train loss: {train_loss:.6f}, dev loss: {val_loss:.6f}, accuracy: {100*val_metric:.2f}\")\n",
        "      print(\"-\"*10)\n",
        "\n",
        "  # load best model weights\n",
        "  model.load_state_dict(best_model_wts)\n",
        "  return model, loss_history, metric_history\n",
        "\n"
      ],
      "metadata": {
        "id": "nC1FDcRQP5Us"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Process\n"
      ],
      "metadata": {
        "id": "W2XbTWy2n62O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define various parameters used for training and evaluation of a cnn_model\n",
        "params_train = {\n",
        "    'train': train_loader,\n",
        "    'val': val_loader,\n",
        "    'epochs': 60,\n",
        "    'optimizer': optim.Adam(cnn_model.parameters(), lr=3e-4),\n",
        "    'lr_change': ReduceLROnPlateau(opt,\n",
        "                                   mode='min',\n",
        "                                   factor=0.5,\n",
        "                                   patience=20,\n",
        "                                   verbose=0),\n",
        "    'f_loss': nn.NLLLoss(reduction='sum'),\n",
        "    'weight_path': 'weight.pt',\n",
        "}\n",
        "\n",
        "# train and validate the model\n",
        "cnn_model, loss_hist, metric_hist = Train_val(cnn_model, params_train)\n"
      ],
      "metadata": {
        "id": "iTQUBd8on9wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation Metric Visualization\n"
      ],
      "metadata": {
        "id": "SBIchjmZpqly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss and Accuracy plot\n",
        "# Convergence History Plot\n",
        "epochs=params_train[\"epochs\"]\n",
        "fig,ax = plt.subplots(1,2,figsize=(12,5))\n",
        "\n",
        "sns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"train\"],ax=ax[0],label='loss_hist[\"train\"]')\n",
        "sns.lineplot(x=[*range(1,epochs+1)],y=loss_hist[\"val\"],ax=ax[0],label='loss_hist[\"val\"]')\n",
        "sns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"train\"],ax=ax[1],label='Acc_hist[\"train\"]')\n",
        "sns.lineplot(x=[*range(1,epochs+1)],y=metric_hist[\"val\"],ax=ax[1],label='Acc_hist[\"val\"]')\n"
      ],
      "metadata": {
        "id": "sMz7y4WdpyY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix\n"
      ],
      "metadata": {
        "id": "qaZfVuoDqEdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define function For Classification Report\n",
        "def Ture_and_Pred(val_loader, model):\n",
        "    i = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.numpy()\n",
        "        outputs = model(images)\n",
        "        _, pred = torch.max(outputs.data, 1)\n",
        "        pred = pred.detach().cpu().numpy()\n",
        "\n",
        "        y_true = np.append(y_true, labels)\n",
        "        y_pred = np.append(y_pred, pred)\n",
        "\n",
        "    return y_true, y_pred\n",
        "\n",
        "\n",
        "# check confusion matrix for error analysis\n",
        "y_true, y_pred = Ture_and_Pred(val_loader, cnn_model)\n",
        "\n",
        "print(classification_report(y_true, y_pred), '\\n\\n')\n",
        "cm = confusion_matrix(y_true, y_pred)\n"
      ],
      "metadata": {
        "id": "xDYr5D7-qJFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion Matrix Plotting Function\n",
        "def show_confusion_matrix(cm, CLA_label, title='Confusion matrix', cmap=plt.cm.YlGnBu):\n",
        "\n",
        "    plt.figure(figsize=(10,7))\n",
        "    plt.grid(False)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(CLA_label))\n",
        "\n",
        "    plt.xticks(tick_marks, [f\"{value}={key}\" for key , value in CLA_label.items()], rotation=45)\n",
        "    plt.yticks(tick_marks, [f\"{value}={key}\" for key , value in CLA_label.items()])\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, f\"{cm[i,j]}\\n{cm[i,j]/np.sum(cm)*100:.2f}%\", horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('Actual')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_confusion_matrix(cm, CLA_label)\n",
        "\n"
      ],
      "metadata": {
        "id": "Y4eHvaqlqXlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Model"
      ],
      "metadata": {
        "id": "XbEg1RmXrLw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(cnn_model, \"Brain_Tumor_model.pt\")\n"
      ],
      "metadata": {
        "id": "qE4zGNodqbdW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}